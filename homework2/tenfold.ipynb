{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用torch库\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#调用numpy库\n",
    "import numpy as np\n",
    "#调用matplotlib库\n",
    "import matplotlib.pyplot as plt\n",
    "#调用random库\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取k折交叉验证某一折的训练集和验证集\n",
    "def get_kfold_data(k, i, X, Y):\n",
    "    fold_size = X.shape[0] // k\n",
    "    val_start = i * fold_size\n",
    "    if i != k - 1:\n",
    "        val_end = (i + 1) * fold_size\n",
    "        X_valid, Y_valid = X[val_start:val_end], Y[val_start:val_end]\n",
    "        X_train = torch.cat([X[0:val_start], X[val_end:]], dim=0)\n",
    "        Y_train = torch.cat([Y[0:val_start], Y[val_end:]], dim=0)\n",
    "    else:\n",
    "        X_valid, Y_valid = X[val_start:], Y[val_start:]\n",
    "        X_train = X[0:val_start]\n",
    "        Y_train = Y[0:val_start]\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid\n",
    "\n",
    "def k_fold_1(k, X_train, Y_train, train_function, para_list):\n",
    "    train_loss_sum, valid_loss_sum = 0, 0\n",
    "    train_acc_sum, valid_acc_sum = 0, 0\n",
    "\n",
    "    for i in range(k):\n",
    "        print('第', i + 1, '折验证结果: ')\n",
    "        data = get_kfold_data(k, i, X_train, Y_train)\n",
    "        train_loss, val_loss = train_function(data, para_list)\n",
    "        print('训练损失：{:.4f}，验证损失：{:.4f}'.format(train_loss, val_loss))\n",
    "\n",
    "        train_loss_sum += train_loss\n",
    "        valid_loss_sum += val_loss\n",
    "\n",
    "    print('最终k折交叉验证结果:')\n",
    "    print('平均训练损失：{:.4f}，平均验证损失：{:.4f}'.format(train_loss_sum/k, valid_loss_sum/k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归模型十折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据生成\n",
    "n_data = torch.zeros(10000, 500)\n",
    "X = torch.normal(mean=n_data, std=n_data + 0.01)\n",
    "\n",
    "n_noise = torch.zeros(10000, 1)\n",
    "noise = torch.normal(mean=n_noise, std=n_noise + 0.01)\n",
    "\n",
    "Y = 0.028 + 0.056*torch.sum(X, dim=1).unsqueeze(1) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用课上给出的数据读取函数\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices) # 样本的读取顺序是随机的\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # 最后一次可能不足一个batch\n",
    "        yield features.index_select(0, j), labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "class Feedforward(nn.Module):\n",
    "  def __init__(self, feature, hidden):\n",
    "    super(Feedforward, self).__init__()\n",
    "    self.hidden = nn.Linear(feature, hidden)\n",
    "    self.out = nn.Linear(hidden, 1)\n",
    " \n",
    "  def forward(self, x):\n",
    "    x = self.hidden(x)\n",
    "    y_hat = self.out(x)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "device = 'cuda:0'\n",
    "epoch_num = 5\n",
    "lr = 0.01\n",
    "feature_dim = 500\n",
    "hidden_dim = 100\n",
    "batch_size = 128\n",
    "# 模型、优化器以及损失函数设置\n",
    "loss = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# 配置列表\n",
    "para_list = [device, epoch_num, lr, feature_dim, hidden_dim, batch_size, loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 适配后的训练函数\n",
    "def train_function(data, para_list):\n",
    "    x_train, y_train, x_valid, y_valid = data\n",
    "    device, epoch_num, lr, feature_dim, hidden_dim, batch_size, loss = para_list\n",
    "    model = Feedforward(feature_dim, hidden_dim).to(device)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        for x, y in data_iter(batch_size, x_train, y_train):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model.forward(x)\n",
    "            l = loss(y_hat, y)\n",
    "            opt.zero_grad()\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_loss_list.append(l.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        counter = 0\n",
    "        for x, y in data_iter(batch_size, x_valid, y_valid):\n",
    "            test_x, test_y = x.to(device), y.to(device)\n",
    "            test_pred = model.forward(test_x)\n",
    "\n",
    "            l = loss(test_pred, test_y).sum()\n",
    "            total_loss += l\n",
    "            counter += 1\n",
    "        test_loss_list.append(total_loss.item())     \n",
    "\n",
    "    train_loss = np.array(train_loss_list).mean()\n",
    "    val_loss = np.array(test_loss_list).mean()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折验证结果: \n",
      "训练损失：0.0004，验证损失：0.0020\n",
      "第 2 折验证结果: \n",
      "训练损失：0.0013，验证损失：0.0021\n",
      "第 3 折验证结果: \n",
      "训练损失：0.0013，验证损失：0.0021\n",
      "第 4 折验证结果: \n",
      "训练损失：0.0003，验证损失：0.0019\n",
      "第 5 折验证结果: \n",
      "训练损失：0.0010，验证损失：0.0019\n",
      "第 6 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0023\n",
      "第 7 折验证结果: \n",
      "训练损失：0.0004，验证损失：0.0023\n",
      "第 8 折验证结果: \n",
      "训练损失：0.0003，验证损失：0.0021\n",
      "第 9 折验证结果: \n",
      "训练损失：0.0003，验证损失：0.0022\n",
      "第 10 折验证结果: \n",
      "训练损失：0.0003，验证损失：0.0021\n",
      "最终k折交叉验证结果:\n",
      "平均训练损失：0.0006，平均验证损失：0.0021\n"
     ]
    }
   ],
   "source": [
    "k_fold_1(10, X, Y, train_function, para_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分类模型十折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据生成\n",
    "n_data = torch.zeros(10000, 200)\n",
    "X1 = torch.normal(mean=n_data + 1, std=n_data + 0.01)\n",
    "Y1 = torch.zeros(10000, 1)\n",
    "\n",
    "X2 = torch.normal(mean=n_data - 1, std=n_data + 0.01)\n",
    "Y2 = torch.ones(10000, 1)\n",
    "\n",
    "X = torch.cat([X1, X2], dim=0)\n",
    "Y = torch.cat([Y1, Y2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用课上给出的数据读取函数\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices) # 样本的读取顺序是随机的\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # 最后一次可能不足一个batch\n",
    "        yield features.index_select(0, j), labels.index_select(0, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "class Feedforward(nn.Module):\n",
    "  def __init__(self, feature, hidden):\n",
    "    super(Feedforward, self).__init__()\n",
    "    self.hidden = nn.Linear(feature, hidden)\n",
    "    self.out = nn.Linear(hidden, 1)\n",
    "    self.act = nn.Sigmoid()\n",
    " \n",
    "  def forward(self, x):\n",
    "    x = self.hidden(x)\n",
    "    x = self.out(x)\n",
    "    return self.act(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "device = 'cuda:0'\n",
    "epoch_num = 100\n",
    "lr = 0.01\n",
    "feature_dim = 200\n",
    "hidden_dim = 100\n",
    "batch_size = 128\n",
    "# 模型、优化器以及损失函数设置\n",
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "# 配置列表\n",
    "para_list = [device, epoch_num, lr, feature_dim, hidden_dim, batch_size, loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 适配后的训练函数\n",
    "def train_function(data, para_list):\n",
    "    x_train, y_train, x_valid, y_valid = data\n",
    "    device, epoch_num, lr, feature_dim, hidden_dim, batch_size, loss = para_list\n",
    "    model = Feedforward(feature_dim, hidden_dim).to(device)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        for x, y in data_iter(batch_size, x_train, y_train):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model.forward(x)\n",
    "            l = loss(y_hat, y)\n",
    "            opt.zero_grad()\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_loss_list.append(l.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        counter = 0\n",
    "        for x, y in data_iter(batch_size, x_valid, y_valid):\n",
    "            test_x, test_y = x.to(device), y.to(device)\n",
    "            test_pred = model.forward(test_x)\n",
    "\n",
    "            l = loss(test_pred, test_y).sum()\n",
    "            total_loss += l\n",
    "            counter += 1\n",
    "        test_loss_list.append(total_loss.item())     \n",
    "\n",
    "    train_loss = np.array(train_loss_list).mean()\n",
    "    val_loss = np.array(test_loss_list).mean()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折验证结果: \n",
      "训练损失：0.0006，验证损失：0.0004\n",
      "第 2 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "第 3 折验证结果: \n",
      "训练损失：0.0004，验证损失：0.0004\n",
      "第 4 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "第 5 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "第 6 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "第 7 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "第 8 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "第 9 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "第 10 折验证结果: \n",
      "训练损失：0.0005，验证损失：0.0004\n",
      "最终k折交叉验证结果:\n",
      "平均训练损失：0.0005，平均验证损失：0.0004\n"
     ]
    }
   ],
   "source": [
    "k_fold_1(10, X, Y, train_function, para_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分类模型十折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作一下这个数据集\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"../Datasets/MNIST\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"../Datasets/MNIST\", train=False, transform=transforms.ToTensor())\n",
    "\n",
    "num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取k折交叉验证某一折的训练集和验证集\n",
    "def get_kfold_data(k, i, train_dataset, test_dataset):\n",
    "    dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
    "    dataset_list = [dataset for dataset in torch.utils.data.random_split(dataset, [len(dataset) // k for i in range(k)])]\n",
    "    if i != k-1:\n",
    "        train_list = dataset_list[0:i] + dataset_list[i+1:]\n",
    "    else:\n",
    "        train_list = dataset_list[0:i]\n",
    "\n",
    "    train_dataset = torch.utils.data.ConcatDataset(train_list)\n",
    "    valid_dataset = dataset_list[i]\n",
    "\n",
    "    return [train_dataset, valid_dataset]\n",
    "\n",
    "def k_fold_2(k, train_dataset, test_dataset, train_function, para_list):\n",
    "    train_loss_sum, valid_loss_sum = 0, 0\n",
    "    train_acc_sum, valid_acc_sum = 0, 0\n",
    "\n",
    "    for i in range(k):\n",
    "        print('第', i + 1, '折验证结果: ')\n",
    "        datasets = get_kfold_data(k, i, train_dataset, test_dataset)\n",
    "        train_loss, val_loss, val_acc = train_function(datasets, para_list)\n",
    "        print('训练损失：{:.4f}，验证损失：{:.4f}，验证精度：{:.3f}%'.format(train_loss, val_loss, val_acc))\n",
    "\n",
    "        train_loss_sum += train_loss\n",
    "        valid_loss_sum += val_loss\n",
    "        valid_acc_sum += val_acc\n",
    "\n",
    "    print('最终k折交叉验证结果:')\n",
    "    print('平均训练损失：{:.4f}，平均验证损失：{:.4f}，平均验证精度：{:.3f}%'.format(train_loss_sum/k, valid_loss_sum/k, valid_acc_sum/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "class FlattenLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, image_size, class_num, layer_num, hidden_dim, activation, drop_out=0):\n",
    "        super(Feedforward, self).__init__()\n",
    "\n",
    "        self.flatten = FlattenLayer()\n",
    "        self.linear_in = nn.Linear(image_size*image_size, hidden_dim)\n",
    "        hidden_layers = []\n",
    "        hidden_layers.append(activation)\n",
    "        if drop_out > 0:\n",
    "            hidden_layers.append(nn.Dropout(p=drop_out))\n",
    "        \n",
    "        for _ in range(layer_num - 1):\n",
    "            hidden_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            hidden_layers.append(activation)\n",
    "            if drop_out > 0:\n",
    "                hidden_layers.append(nn.Dropout(p=drop_out))\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "        self.linear_out = nn.Linear(hidden_dim, class_num)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_in(x)\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.linear_out(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "epoch_num = 20\n",
    "lr = 0.03\n",
    "image_size = 28\n",
    "class_num = 10\n",
    "device = 'cuda:0'\n",
    "batch_size = 32\n",
    "\n",
    "layer_num  = 1   # 隐藏层数为1层\n",
    "hidden_dim = 100 # 隐藏层单元数为100\n",
    "drop_out   = 0   # 不设置dropout\n",
    "lambd      = 0   # 不设置正则化项\n",
    "activation = nn.ReLU() # 激活函数设置为ReLU\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "para_list = [epoch_num, lr, image_size, class_num, device, layer_num, hidden_dim, drop_out, lambd, activation, loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算预测的准确度\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 适配后的训练函数\n",
    "def train_function(datasets, para_list):\n",
    "    train_dataset, valid_dataset = datasets\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    epoch_num, lr, image_size, class_num, device, layer_num, hidden_dim, drop_out, lambd, activation, loss = para_list\n",
    "    model = Feedforward(image_size=image_size, class_num=class_num, layer_num=layer_num, hidden_dim=hidden_dim, activation=activation, drop_out=drop_out).to(device)\n",
    "    opt = torch.optim.SGD(model.parameters(), lr = lr, weight_decay=lambd)\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    test_acc_list = []\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        for i, datas in enumerate(train_loader):\n",
    "            train_x, train_label = datas[0].to(device), datas[1].to(device)\n",
    "            train_pred = model.forward(train_x)\n",
    "            l = loss(train_pred, train_label).sum()\n",
    "            opt.zero_grad()\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "            train_loss_list.append(l.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, datas in enumerate(valid_loader):\n",
    "            test_x, test_label = datas[0].to(device), datas[1].to(device)\n",
    "            test_pred = model.forward(test_x)\n",
    "\n",
    "            l = loss(test_pred, test_label).sum()\n",
    "            total_loss += l\n",
    "\n",
    "            acc = accuracy(test_pred, test_label) / len(test_pred)\n",
    "            total_acc += acc\n",
    "\n",
    "        test_loss_list.append(total_loss.item())\n",
    "        test_acc_list.append(acc)\n",
    "\n",
    "    train_loss = np.array(train_loss_list).mean()\n",
    "    val_loss = np.array(test_loss_list).mean()\n",
    "    val_acc = np.array(test_acc_list).mean()\n",
    "    return train_loss, val_loss/100, val_acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折验证结果: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_960443/1595188733.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失：1.5724，验证损失：3.3506，验证精度：91.667%\n",
      "第 2 折验证结果: \n",
      "训练损失：1.5744，验证损失：3.3351，验证精度：91.667%\n",
      "第 3 折验证结果: \n",
      "训练损失：1.5716，验证损失：3.3439，验证精度：87.500%\n",
      "第 4 折验证结果: \n",
      "训练损失：1.5751，验证损失：3.3605，验证精度：95.833%\n",
      "第 5 折验证结果: \n",
      "训练损失：1.5877，验证损失：3.3567，验证精度：95.833%\n",
      "第 6 折验证结果: \n",
      "训练损失：1.6150，验证损失：3.3627，验证精度：95.833%\n",
      "第 7 折验证结果: \n",
      "训练损失：1.5740，验证损失：3.3344，验证精度：95.833%\n",
      "第 8 折验证结果: \n",
      "训练损失：1.5688，验证损失：3.3491，验证精度：91.667%\n",
      "第 9 折验证结果: \n",
      "训练损失：1.5704，验证损失：3.3518，验证精度：91.667%\n",
      "第 10 折验证结果: \n",
      "训练损失：1.5806，验证损失：3.3531，验证精度：95.833%\n",
      "最终k折交叉验证结果:\n",
      "平均训练损失：1.5790，平均验证损失：3.3498，平均验证精度：93.333%\n"
     ]
    }
   ],
   "source": [
    "k_fold_2(10, train_dataset, test_dataset, train_function, para_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb47ef1ad79943d811bafa2fa84fcb47147f85a402b583945e5888afc6d949fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
